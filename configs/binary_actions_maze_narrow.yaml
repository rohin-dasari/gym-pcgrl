algorithm: PPO
is_parallel: true
is_grouped: false
rllib_trainer_config:
    # Rllib trainer config
    env: Parallel_MAPcgrl-binary-marl_narrow-v0
    env_config:
        binary_actions: True
        max_iterations: 500
    num_gpus: 0
    framework: torch
    output: experiments
    render_env: false
    lr: 0.0001
tune_api_config:
    ####################
    # Tune API parameters
    stop:
        training_iteration: 2
    mode: max
    metric: episode_reward_mean
    checkpoint_score_attr: episode_reward_mean
    keep_checkpoints_num: 3
    checkpoint_freq: 1
    checkpoint_at_end: true
####################
# model config
model_config: 
    custom_model: CustomFeedForwardModel
####################
