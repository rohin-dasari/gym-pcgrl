# Rllib trainer config
env: Parallel_MAPcgrl-binary-narrow-v0
env_config:
    num_agents: 2
    binary_actions: False
num_gpus: 0
framework: torch
render_env: false
####################
# Tune API parameters -> currently not accounted for when loading config
algorithm: PPO
stop:
    training_iteration: 2
mode: max
metric: episode_reward_mean
checkpoint_score_attr: episode_reward_mean
keep_checkpoints_num: 3
checkpoint_freq: 1
checkpoint_at_end: true
# 
####################
# model config
model_config: 
    custom_model: CustomFeedForwardModel
####################
